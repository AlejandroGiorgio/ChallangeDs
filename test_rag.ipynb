{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo con la implementacion de llama index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragmento de codigo para embeber el libro de forma manual sin usar la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Cargar el PDF (usará pdfplumber internamente)\n",
    "documents = SimpleDirectoryReader(input_files=[\"Juego de tronos - Canción de hielo y fuego 1.pdf\"]).load_data()\n",
    "\n",
    "# Usar un parser que haga chunking eficiente\n",
    "parser = SentenceSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "# Usar embeddings de Hugging Face\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "# Construir el índice\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, text_splitter=parser)\n",
    "\n",
    "# Guardar el índice para reutilizarlo\n",
    "index.storage_context.persist(\"llamaindex_got\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Alejandro\\Documents\\Python Scripts\\ChallangeDs\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Ruta donde guardaste el índice previamente\n",
    "index_path = \"llamaindex_got\"\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "# Cargar el índice desde el almacenamiento\n",
    "storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "index = load_index_from_storage(storage_context, embed_model=embed_model)\n",
    "\n",
    "# Crear un motor de consulta\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viserys Targaryen.\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la consulta\n",
    "response = query_engine.query(\"A quien le vertieron oro fundido en la cabeza?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 \n",
      "Dany, diles... haz que... hermanita... \n",
      "Cuando el oro estuvo medio fundido, casi líquido, D rogo cogió el caldero. \n",
      "—¡Corona! —rugió—. Aquí. ¡Una corona para Rey del C arro! —Y puso el \n",
      "caldero en la cabeza del hombre que había sido su h ermano. \n",
      "El sonido que emitió Viserys Targaryen cuando aquel  espantoso yelmo de hierro \n",
      "le cubrió la cara no fue humano. Sus pies marcaron un ritmo frenético en el suelo de \n",
      "tierra, se agitaron y al final se detuvieron. Sobre  el pecho le cayeron goterones de oro \n",
      "fundido, y la seda escarlata empezó a humear... per o no se derramó ni una gota de \n",
      "sangre. \n",
      "Dany se sentía extrañamente tranquila. \n",
      "«No era un dragón —pensó—. El fuego no mata a un dr agón.»\n",
      "--------------------------------------------------\n",
      "La espada de Chiggen destrozó el rostro descubierto  de un jinete que vestía cota de \n",
      "mallas, y Bronn cayó entre sus enemigos como un hur acán, repartiendo golpes a diestro \n",
      "y siniestro. Ser Rodrik se enfrentó al hombretón de  la capa de gatosombra, los caballos \n",
      "giraban el uno en torno al otro mientras ellos camb iaban golpe por golpe. Jyck montó a \n",
      "un caballo y se lanzó al galope al centro de la ref riega. De repente, Tyrion vio que el \n",
      "hombre de la capa de gatosombra tenía una flecha en  la garganta. Cuando abrió la boca \n",
      "para gritar, lo único que salió fue sangre. Cuando su cadáver llegó al suelo Ser Rodrik \n",
      "ya estaba peleando con otro hombre. \n",
      "De pronto, Marillion dejó escapar un grito y se cub rió la cabeza con la lira. Un \n",
      "caballo salvó de un salto la roca tras la que se oc ultaban. Mientras el jinete daba la \n",
      "vuelta para enfrentarse a ellos, haciendo girar una  maza con púas, Tyrion consiguió \n",
      "ponerse en pie y blandir el hacha con ambas manos. La hoja se clavó en la garganta del \n",
      "caballo cuando éste cargó contra ellos, y el mango estuvo a punto de escapársele de las \n",
      "manos mientras el animal relinchaba y se derrumbaba . Consiguió recuperar el arma y \n",
      "apartarse del camino justo a tiempo. Marillion no t uvo tanta suerte: el caballo y su jinete \n",
      "cayeron justo encima del bardo. Tyrion retrocedió u n paso aprovechando que la pierna \n",
      "del bandolero había quedado atrapada bajo la montur a, y enterró el hacha en el cuello \n",
      "del hombre, por encima de los omoplatos.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El RAG trae una respuesta, la cual es bastante escueta y fragmentos de texto. El modelo no reaccionó bien a estos fragmentos, por lo que se opto solo por devolver la respuesta y el numero de las pagians"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
